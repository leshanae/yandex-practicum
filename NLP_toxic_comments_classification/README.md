## Постановка задачи
*Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.*

*Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.*

*Постройте модель со значением метрики качества F1 не меньше 0.75.*

#### Описание данных
*Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.*

## Детали проекта
Была взята выгрузка твитов из социальной сети twitter, проведена лемматизация и очистка текста при помощи пакета Spacy, обучено несколько моделей. Проведён анализ результатов лучшей модели на тестовой выборке.

## Вывод
В ходе работы получилось построить модель для бинарной классификации на основе логистической регрессии, получив на тесте метрику F1 равной 0,776.  
Модели на основе CatBoost и LGBM могут быть обучены на очень высокий уровень распознавания текста, однако для этого требуются хорошие вычислительные мощности, тогда как "привычная" логистическая регрессия даёт приемлемый результат для оперативных задач на обычном ноутбуке. Но возможно ли вытянуть её на большие метрики? Это вопрос более подробного исследования.